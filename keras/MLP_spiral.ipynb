{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP spiral.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-vO_qr2EFdss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSnMdos9Fdsw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# spiral"
      ]
    },
    {
      "metadata": {
        "id": "b7cgJGEHFdsx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from math import *\n",
        "theta = np.empty(0)\n",
        "for i in range(7):  \n",
        "    theta = np.append(theta, np.linspace(i*pi/2, (i+1)*pi/2, 4*i + 4))\n",
        "r = theta\n",
        "ax = r * np.cos(theta)\n",
        "ay = r * np.sin(theta)\n",
        "bx = -r * np.cos(theta)\n",
        "by = -r * np.sin(theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OK49wW75bEQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "49c249c7-323a-4e3d-a2a1-49865c819645"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(ax, ay)\n",
        "plt.scatter(bx, by)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f191a95c588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAD8CAYAAABtq/EAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "r917-JbsFdtN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# combine"
      ]
    },
    {
      "metadata": {
        "id": "1LVp8HY-FdtO",
        "colab_type": "code",
        "outputId": "525985dc-a5b4-4fc7-96f2-c21c014854be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "label = np.append(np.zeros(ax.shape[0]), np.ones(bx.shape[0]))\n",
        "label.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "xz6X6-CgFdtS",
        "colab_type": "code",
        "outputId": "9f419104-bc43-4e64-e32e-3d5535d693bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x = np.append(ax, bx)\n",
        "y = np.append(ay, by)\n",
        "x.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "1_QJQKwsGwCk",
        "colab_type": "code",
        "outputId": "e0b7c2bc-7d0c-434c-9de9-6b6a7bfac6d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.stack((x, y), axis=-1)\n",
        "X.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "hBEVukxkIRn1",
        "colab_type": "code",
        "outputId": "756d8548-6999-48f9-e3b2-3b229cedc664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "f = np.random.rand(X.shape[0]) < 0.8\n",
        "Xtrain = X[f]\n",
        "Xtest = X[~f]\n",
        "label_train = label[f]\n",
        "label_test = label[~f]\n",
        "print(Xtrain.shape)\n",
        "print(Xtest.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(173, 2)\n",
            "(51, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bUNJ9KNhFdtV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# learning"
      ]
    },
    {
      "metadata": {
        "id": "bBg_xjdQFdtW",
        "colab_type": "code",
        "outputId": "703f8d91-5978-431b-d87d-38cae02de93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "TVMn4tGHGGc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TOTAL_CLASS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "90um42sQFdtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "        Dense(128, activation='relu'),    \n",
        "        Dense(64, activation='relu'),    \n",
        "        Dense(32, activation='relu'),    \n",
        "        Dense(2, activation='softmax'),    \n",
        "]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKdfQAdBHGQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0b46dc30-605d-40a7-e869-1e775d968910"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SC7TJnlCHGqL",
        "colab_type": "code",
        "outputId": "8ca6add2-b288-4cd0-cfd5-b364177ad8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6824
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain, label_train, epochs=200) # , shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/200\n",
            "173/173 [==============================] - 0s 927us/step - loss: 0.7296 - acc: 0.5376\n",
            "Epoch 2/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.6492 - acc: 0.6301\n",
            "Epoch 3/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.6353 - acc: 0.6127\n",
            "Epoch 4/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.6255 - acc: 0.6243\n",
            "Epoch 5/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.6237 - acc: 0.6416\n",
            "Epoch 6/200\n",
            "173/173 [==============================] - 0s 91us/step - loss: 0.6191 - acc: 0.6358\n",
            "Epoch 7/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.6258 - acc: 0.6474\n",
            "Epoch 8/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.6179 - acc: 0.6416\n",
            "Epoch 9/200\n",
            "173/173 [==============================] - 0s 66us/step - loss: 0.6178 - acc: 0.6474\n",
            "Epoch 10/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.6184 - acc: 0.6358\n",
            "Epoch 11/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.6163 - acc: 0.6416\n",
            "Epoch 12/200\n",
            "173/173 [==============================] - 0s 65us/step - loss: 0.6186 - acc: 0.6358\n",
            "Epoch 13/200\n",
            "173/173 [==============================] - 0s 91us/step - loss: 0.6156 - acc: 0.6474\n",
            "Epoch 14/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.6136 - acc: 0.6416\n",
            "Epoch 15/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.6184 - acc: 0.6474\n",
            "Epoch 16/200\n",
            "173/173 [==============================] - 0s 77us/step - loss: 0.6130 - acc: 0.6474\n",
            "Epoch 17/200\n",
            "173/173 [==============================] - 0s 68us/step - loss: 0.6194 - acc: 0.6358\n",
            "Epoch 18/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.6149 - acc: 0.6416\n",
            "Epoch 19/200\n",
            "173/173 [==============================] - 0s 85us/step - loss: 0.6135 - acc: 0.6358\n",
            "Epoch 20/200\n",
            "173/173 [==============================] - 0s 95us/step - loss: 0.6168 - acc: 0.6358\n",
            "Epoch 21/200\n",
            "173/173 [==============================] - 0s 60us/step - loss: 0.6159 - acc: 0.6358\n",
            "Epoch 22/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.6110 - acc: 0.6474\n",
            "Epoch 23/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.6112 - acc: 0.6590\n",
            "Epoch 24/200\n",
            "173/173 [==============================] - 0s 56us/step - loss: 0.6123 - acc: 0.6474\n",
            "Epoch 25/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.6141 - acc: 0.6358\n",
            "Epoch 26/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.6125 - acc: 0.6416\n",
            "Epoch 27/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.6160 - acc: 0.6358\n",
            "Epoch 28/200\n",
            "173/173 [==============================] - 0s 56us/step - loss: 0.6096 - acc: 0.6243\n",
            "Epoch 29/200\n",
            "173/173 [==============================] - 0s 87us/step - loss: 0.6135 - acc: 0.6358\n",
            "Epoch 30/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.6099 - acc: 0.6474\n",
            "Epoch 31/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.6092 - acc: 0.6474\n",
            "Epoch 32/200\n",
            "173/173 [==============================] - 0s 84us/step - loss: 0.6102 - acc: 0.6358\n",
            "Epoch 33/200\n",
            "173/173 [==============================] - 0s 104us/step - loss: 0.6131 - acc: 0.6474\n",
            "Epoch 34/200\n",
            "173/173 [==============================] - 0s 85us/step - loss: 0.6065 - acc: 0.6416\n",
            "Epoch 35/200\n",
            "173/173 [==============================] - 0s 79us/step - loss: 0.6105 - acc: 0.6416\n",
            "Epoch 36/200\n",
            "173/173 [==============================] - 0s 65us/step - loss: 0.6089 - acc: 0.6301\n",
            "Epoch 37/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.6063 - acc: 0.6358\n",
            "Epoch 38/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.6084 - acc: 0.6243\n",
            "Epoch 39/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.6031 - acc: 0.6358\n",
            "Epoch 40/200\n",
            "173/173 [==============================] - 0s 99us/step - loss: 0.6068 - acc: 0.6474\n",
            "Epoch 41/200\n",
            "173/173 [==============================] - 0s 78us/step - loss: 0.6113 - acc: 0.6532\n",
            "Epoch 42/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.6030 - acc: 0.6301\n",
            "Epoch 43/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.6082 - acc: 0.6243\n",
            "Epoch 44/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.6102 - acc: 0.6301\n",
            "Epoch 45/200\n",
            "173/173 [==============================] - 0s 93us/step - loss: 0.6058 - acc: 0.6416\n",
            "Epoch 46/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.6035 - acc: 0.6532\n",
            "Epoch 47/200\n",
            "173/173 [==============================] - 0s 66us/step - loss: 0.6047 - acc: 0.6358\n",
            "Epoch 48/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.6043 - acc: 0.6301\n",
            "Epoch 49/200\n",
            "173/173 [==============================] - 0s 85us/step - loss: 0.6022 - acc: 0.6127\n",
            "Epoch 50/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.6061 - acc: 0.6358\n",
            "Epoch 51/200\n",
            "173/173 [==============================] - 0s 66us/step - loss: 0.6016 - acc: 0.6301\n",
            "Epoch 52/200\n",
            "173/173 [==============================] - 0s 77us/step - loss: 0.6027 - acc: 0.6301\n",
            "Epoch 53/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.5978 - acc: 0.6590\n",
            "Epoch 54/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.6119 - acc: 0.6763\n",
            "Epoch 55/200\n",
            "173/173 [==============================] - 0s 78us/step - loss: 0.6059 - acc: 0.6705\n",
            "Epoch 56/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.5991 - acc: 0.6474\n",
            "Epoch 57/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.5956 - acc: 0.6301\n",
            "Epoch 58/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.5985 - acc: 0.6532\n",
            "Epoch 59/200\n",
            "173/173 [==============================] - 0s 68us/step - loss: 0.5949 - acc: 0.6474\n",
            "Epoch 60/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.5916 - acc: 0.6243\n",
            "Epoch 61/200\n",
            "173/173 [==============================] - 0s 88us/step - loss: 0.5965 - acc: 0.6243\n",
            "Epoch 62/200\n",
            "173/173 [==============================] - 0s 99us/step - loss: 0.5923 - acc: 0.6358\n",
            "Epoch 63/200\n",
            "173/173 [==============================] - 0s 113us/step - loss: 0.5906 - acc: 0.6243\n",
            "Epoch 64/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.5931 - acc: 0.6243\n",
            "Epoch 65/200\n",
            "173/173 [==============================] - 0s 58us/step - loss: 0.5919 - acc: 0.6243\n",
            "Epoch 66/200\n",
            "173/173 [==============================] - 0s 63us/step - loss: 0.5883 - acc: 0.6243\n",
            "Epoch 67/200\n",
            "173/173 [==============================] - 0s 58us/step - loss: 0.5864 - acc: 0.6127\n",
            "Epoch 68/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.5906 - acc: 0.6243\n",
            "Epoch 69/200\n",
            "173/173 [==============================] - 0s 77us/step - loss: 0.5866 - acc: 0.6416\n",
            "Epoch 70/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.5816 - acc: 0.6416\n",
            "Epoch 71/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.5804 - acc: 0.6416\n",
            "Epoch 72/200\n",
            "173/173 [==============================] - 0s 65us/step - loss: 0.5850 - acc: 0.6416\n",
            "Epoch 73/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.5758 - acc: 0.6243\n",
            "Epoch 74/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.5763 - acc: 0.6185\n",
            "Epoch 75/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.5826 - acc: 0.6185\n",
            "Epoch 76/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.5741 - acc: 0.6243\n",
            "Epoch 77/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.5667 - acc: 0.6474\n",
            "Epoch 78/200\n",
            "173/173 [==============================] - 0s 57us/step - loss: 0.5633 - acc: 0.6474\n",
            "Epoch 79/200\n",
            "173/173 [==============================] - 0s 62us/step - loss: 0.5684 - acc: 0.6243\n",
            "Epoch 80/200\n",
            "173/173 [==============================] - 0s 63us/step - loss: 0.5549 - acc: 0.6705\n",
            "Epoch 81/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.5580 - acc: 0.6301\n",
            "Epoch 82/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.5489 - acc: 0.6532\n",
            "Epoch 83/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.5495 - acc: 0.6532\n",
            "Epoch 84/200\n",
            "173/173 [==============================] - 0s 123us/step - loss: 0.5377 - acc: 0.6705\n",
            "Epoch 85/200\n",
            "173/173 [==============================] - 0s 89us/step - loss: 0.5351 - acc: 0.6821\n",
            "Epoch 86/200\n",
            "173/173 [==============================] - 0s 82us/step - loss: 0.5329 - acc: 0.7110\n",
            "Epoch 87/200\n",
            "173/173 [==============================] - 0s 87us/step - loss: 0.5258 - acc: 0.7110\n",
            "Epoch 88/200\n",
            "173/173 [==============================] - 0s 85us/step - loss: 0.5180 - acc: 0.7168\n",
            "Epoch 89/200\n",
            "173/173 [==============================] - 0s 92us/step - loss: 0.5146 - acc: 0.6936\n",
            "Epoch 90/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.5055 - acc: 0.6879\n",
            "Epoch 91/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.4993 - acc: 0.7052\n",
            "Epoch 92/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.4960 - acc: 0.6994\n",
            "Epoch 93/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.4954 - acc: 0.7168\n",
            "Epoch 94/200\n",
            "173/173 [==============================] - 0s 64us/step - loss: 0.4838 - acc: 0.6994\n",
            "Epoch 95/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.4696 - acc: 0.7399\n",
            "Epoch 96/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.4707 - acc: 0.6994\n",
            "Epoch 97/200\n",
            "173/173 [==============================] - 0s 68us/step - loss: 0.4623 - acc: 0.7341\n",
            "Epoch 98/200\n",
            "173/173 [==============================] - 0s 83us/step - loss: 0.4524 - acc: 0.7341\n",
            "Epoch 99/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.4564 - acc: 0.7572\n",
            "Epoch 100/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.4318 - acc: 0.7399\n",
            "Epoch 101/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.4292 - acc: 0.7514\n",
            "Epoch 102/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.4034 - acc: 0.7919\n",
            "Epoch 103/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.3958 - acc: 0.7919\n",
            "Epoch 104/200\n",
            "173/173 [==============================] - 0s 87us/step - loss: 0.3864 - acc: 0.8150\n",
            "Epoch 105/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.3770 - acc: 0.8092\n",
            "Epoch 106/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.3753 - acc: 0.8092\n",
            "Epoch 107/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.3666 - acc: 0.7919\n",
            "Epoch 108/200\n",
            "173/173 [==============================] - 0s 62us/step - loss: 0.3540 - acc: 0.8266\n",
            "Epoch 109/200\n",
            "173/173 [==============================] - 0s 63us/step - loss: 0.3424 - acc: 0.8497\n",
            "Epoch 110/200\n",
            "173/173 [==============================] - 0s 80us/step - loss: 0.3249 - acc: 0.8613\n",
            "Epoch 111/200\n",
            "173/173 [==============================] - 0s 79us/step - loss: 0.3168 - acc: 0.8671\n",
            "Epoch 112/200\n",
            "173/173 [==============================] - 0s 79us/step - loss: 0.3059 - acc: 0.8728\n",
            "Epoch 113/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.2967 - acc: 0.8786\n",
            "Epoch 114/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.2842 - acc: 0.8960\n",
            "Epoch 115/200\n",
            "173/173 [==============================] - 0s 68us/step - loss: 0.2664 - acc: 0.9017\n",
            "Epoch 116/200\n",
            "173/173 [==============================] - 0s 59us/step - loss: 0.2542 - acc: 0.9191\n",
            "Epoch 117/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.2425 - acc: 0.8960\n",
            "Epoch 118/200\n",
            "173/173 [==============================] - 0s 64us/step - loss: 0.2391 - acc: 0.9595\n",
            "Epoch 119/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.2156 - acc: 0.9595\n",
            "Epoch 120/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.2051 - acc: 0.9711\n",
            "Epoch 121/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.1910 - acc: 0.9884\n",
            "Epoch 122/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.1760 - acc: 0.9827\n",
            "Epoch 123/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.1638 - acc: 0.9827\n",
            "Epoch 124/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.1472 - acc: 0.9942\n",
            "Epoch 125/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.1362 - acc: 0.9942\n",
            "Epoch 126/200\n",
            "173/173 [==============================] - 0s 83us/step - loss: 0.1256 - acc: 1.0000\n",
            "Epoch 127/200\n",
            "173/173 [==============================] - 0s 79us/step - loss: 0.1163 - acc: 1.0000\n",
            "Epoch 128/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.1066 - acc: 1.0000\n",
            "Epoch 129/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.0989 - acc: 1.0000\n",
            "Epoch 130/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.0920 - acc: 1.0000\n",
            "Epoch 131/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.0841 - acc: 1.0000\n",
            "Epoch 132/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.0791 - acc: 1.0000\n",
            "Epoch 133/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.0762 - acc: 0.9942\n",
            "Epoch 134/200\n",
            "173/173 [==============================] - 0s 86us/step - loss: 0.0698 - acc: 1.0000\n",
            "Epoch 135/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.0657 - acc: 1.0000\n",
            "Epoch 136/200\n",
            "173/173 [==============================] - 0s 65us/step - loss: 0.0619 - acc: 1.0000\n",
            "Epoch 137/200\n",
            "173/173 [==============================] - 0s 79us/step - loss: 0.0569 - acc: 1.0000\n",
            "Epoch 138/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.0554 - acc: 1.0000\n",
            "Epoch 139/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.0510 - acc: 1.0000\n",
            "Epoch 140/200\n",
            "173/173 [==============================] - 0s 58us/step - loss: 0.0467 - acc: 1.0000\n",
            "Epoch 141/200\n",
            "173/173 [==============================] - 0s 67us/step - loss: 0.0432 - acc: 1.0000\n",
            "Epoch 142/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.0400 - acc: 1.0000\n",
            "Epoch 143/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.0384 - acc: 1.0000\n",
            "Epoch 144/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.0374 - acc: 1.0000\n",
            "Epoch 145/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.0345 - acc: 1.0000\n",
            "Epoch 146/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.0328 - acc: 1.0000\n",
            "Epoch 147/200\n",
            "173/173 [==============================] - 0s 77us/step - loss: 0.0308 - acc: 1.0000\n",
            "Epoch 148/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.0294 - acc: 1.0000\n",
            "Epoch 149/200\n",
            "173/173 [==============================] - 0s 88us/step - loss: 0.0282 - acc: 1.0000\n",
            "Epoch 150/200\n",
            "173/173 [==============================] - 0s 62us/step - loss: 0.0273 - acc: 1.0000\n",
            "Epoch 151/200\n",
            "173/173 [==============================] - 0s 66us/step - loss: 0.0263 - acc: 1.0000\n",
            "Epoch 152/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.0252 - acc: 1.0000\n",
            "Epoch 153/200\n",
            "173/173 [==============================] - 0s 65us/step - loss: 0.0236 - acc: 1.0000\n",
            "Epoch 154/200\n",
            "173/173 [==============================] - 0s 55us/step - loss: 0.0229 - acc: 1.0000\n",
            "Epoch 155/200\n",
            "173/173 [==============================] - 0s 63us/step - loss: 0.0224 - acc: 1.0000\n",
            "Epoch 156/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.0219 - acc: 1.0000\n",
            "Epoch 157/200\n",
            "173/173 [==============================] - 0s 60us/step - loss: 0.0209 - acc: 1.0000\n",
            "Epoch 158/200\n",
            "173/173 [==============================] - 0s 116us/step - loss: 0.0199 - acc: 1.0000\n",
            "Epoch 159/200\n",
            "173/173 [==============================] - 0s 72us/step - loss: 0.0191 - acc: 1.0000\n",
            "Epoch 160/200\n",
            "173/173 [==============================] - 0s 78us/step - loss: 0.0187 - acc: 1.0000\n",
            "Epoch 161/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.0177 - acc: 1.0000\n",
            "Epoch 162/200\n",
            "173/173 [==============================] - 0s 84us/step - loss: 0.0172 - acc: 1.0000\n",
            "Epoch 163/200\n",
            "173/173 [==============================] - 0s 77us/step - loss: 0.0165 - acc: 1.0000\n",
            "Epoch 164/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.0160 - acc: 1.0000\n",
            "Epoch 165/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.0161 - acc: 1.0000\n",
            "Epoch 166/200\n",
            "173/173 [==============================] - 0s 66us/step - loss: 0.0152 - acc: 1.0000\n",
            "Epoch 167/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.0148 - acc: 1.0000\n",
            "Epoch 168/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.0143 - acc: 1.0000\n",
            "Epoch 169/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.0140 - acc: 1.0000\n",
            "Epoch 170/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.0137 - acc: 1.0000\n",
            "Epoch 171/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.0134 - acc: 1.0000\n",
            "Epoch 172/200\n",
            "173/173 [==============================] - 0s 86us/step - loss: 0.0131 - acc: 1.0000\n",
            "Epoch 173/200\n",
            "173/173 [==============================] - 0s 77us/step - loss: 0.0123 - acc: 1.0000\n",
            "Epoch 174/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.0119 - acc: 1.0000\n",
            "Epoch 175/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 176/200\n",
            "173/173 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 177/200\n",
            "173/173 [==============================] - 0s 78us/step - loss: 0.0110 - acc: 1.0000\n",
            "Epoch 178/200\n",
            "173/173 [==============================] - 0s 73us/step - loss: 0.0107 - acc: 1.0000\n",
            "Epoch 179/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.0106 - acc: 1.0000\n",
            "Epoch 180/200\n",
            "173/173 [==============================] - 0s 78us/step - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 181/200\n",
            "173/173 [==============================] - 0s 81us/step - loss: 0.0098 - acc: 1.0000\n",
            "Epoch 182/200\n",
            "173/173 [==============================] - 0s 87us/step - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 183/200\n",
            "173/173 [==============================] - 0s 69us/step - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 184/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.0091 - acc: 1.0000\n",
            "Epoch 185/200\n",
            "173/173 [==============================] - 0s 83us/step - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 186/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.0088 - acc: 1.0000\n",
            "Epoch 187/200\n",
            "173/173 [==============================] - 0s 70us/step - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 188/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.0084 - acc: 1.0000\n",
            "Epoch 189/200\n",
            "173/173 [==============================] - 0s 64us/step - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 190/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 191/200\n",
            "173/173 [==============================] - 0s 84us/step - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 192/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 193/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 194/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 195/200\n",
            "173/173 [==============================] - 0s 74us/step - loss: 0.0071 - acc: 1.0000\n",
            "Epoch 196/200\n",
            "173/173 [==============================] - 0s 71us/step - loss: 0.0069 - acc: 1.0000\n",
            "Epoch 197/200\n",
            "173/173 [==============================] - 0s 68us/step - loss: 0.0069 - acc: 1.0000\n",
            "Epoch 198/200\n",
            "173/173 [==============================] - 0s 76us/step - loss: 0.0067 - acc: 1.0000\n",
            "Epoch 199/200\n",
            "173/173 [==============================] - 0s 75us/step - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 200/200\n",
            "173/173 [==============================] - 0s 66us/step - loss: 0.0063 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f190249dc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "JiFByiUzHVqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bdae0917-b87c-4fc5-d1d1-67c8dbddb1f8"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(Xtest, label_test)  \n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 672us/step\n",
            "Test accuracy: 0.9803921568627451\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}